{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1LsYKMM6ue5lVZcSB6o2Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolphinxyz/mlModel/blob/main/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import absolute\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from hyperopt import hp, tpe, fmin\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "RB_juGROzm4n"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns = [\n",
        "  'att_age_13-17', 'att_age_18-24', 'att_age_25-34',\n",
        "  'att_age_35-44', 'att_age_45-55', 'att_age_55+', 'Views_Infludata',\n",
        "  'Engagement_Infludata', 'Quality score', 'Gender_Male%_Infludata',\n",
        "  'Gender_Female%_Infludata', 'Followers', 'Posts', 'AudienceCountryGermany']\n",
        "categorical_columns = [\n",
        "  'InfluencerManager', 'size', 'affinity', 'gender', 'att_cat_empowerment',\n",
        "  'att_cat_family', 'att_cat_interior', 'att_cat_lifestyle', 'att_cat_medical',\n",
        "  'att_cat_sales', 'att_cat_skincare', 'att_cat_beauty-and-makeup',\n",
        "  'att_cat_fashion', 'att_cat_healthy', 'att_cat_personality',\n",
        "  'att_cat_international', 'att_cat_slow-aging', 'att_cat_natural',\n",
        "  'att_cat_fake', 'status', 'IsAudienceCountryGermany>60%', 'IsFemale>60%',\n",
        "  'IsRealAccount>60%']\n",
        "model_columns = ['att_age_13-17', 'att_age_18-24', 'att_age_25-34',\n",
        "  'att_age_35-44', 'att_age_45-55', 'att_age_55+', 'Views_Infludata',\n",
        "  'Engagement_Infludata', 'Quality score', 'Posts', 'InfluencerManager', 'size',\n",
        "  'affinity', 'gender', 'att_cat_empowerment', 'att_cat_family', 'att_cat_interior',\n",
        "  'att_cat_lifestyle', 'att_cat_medical', 'att_cat_sales', 'att_cat_skincare',\n",
        "  'att_cat_beauty-and-makeup', 'att_cat_fashion', 'att_cat_healthy',\n",
        "  'att_cat_personality', 'att_cat_international', 'att_cat_slow-aging',\n",
        "  'att_cat_natural', 'att_cat_fake', 'status', 'IsAudienceCountryGermany>60%',\n",
        "  'IsFemale>60%', 'IsRealAccount>60%']"
      ],
      "metadata": {
        "id": "w_NLFF9rzq-y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    df[\"Orders/Followers\"] = df[\"Orders\"] / (df[\"Followers\"] / 1000)\n",
        "    df[\"AudienceCountryGermany\"] =  df[\"Audience Analysis: Country\"].apply(lambda x: re.search(r'Germany: (.*?)%', str(x)).group(1))\n",
        "    df[\"AudienceCountryGermany\"] = df[\"AudienceCountryGermany\"].astype(float)\n",
        "    df[\"IsAudienceCountryGermany>60%\"] = df[\"AudienceCountryGermany\"] >= 60\n",
        "    df[\"IsFemale>60%\"] = df[\"Gender_Female%_Infludata\"] >= 60\n",
        "    df[\"IsRealAccount>60%\"] = df[\"Audience Analysis: Real Accounts (%)\"] >= 60\n",
        "\n",
        "def manage_missing_data(df):\n",
        "    for numerical_column in numerical_columns:\n",
        "        if df[numerical_column].isnull().values.any():\n",
        "            df[numerical_column + '_isnull'] = np.where(df[numerical_column].isnull(), '1', '0')\n",
        "            df[numerical_column].fillna(value=df[numerical_column].median(), inplace=True)\n",
        "    for categorical_column in categorical_columns:\n",
        "        df[categorical_column].fillna('NULL', inplace=True)\n",
        "\n",
        "def standardize_data(df):\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    df[numerical_columns] = pd.DataFrame(min_max_scaler.fit_transform(df[numerical_columns]))\n",
        "\n",
        "def convert_categorical_data(df):\n",
        "    for column in categorical_columns:\n",
        "        df[column] = LabelEncoder().fit_transform(df[column].astype(str))\n",
        "        df[column] = df[column].astype('category')"
      ],
      "metadata": {
        "id": "wZ-GMGN8zvm4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "goal = [\"Orders/Followers\"]\n",
        "input_df = pd.read_csv(\"InfluencerProfiles.csv\")\n",
        "preprocess_data(input_df)\n",
        "manage_missing_data(input_df)\n",
        "standardize_data(input_df)\n",
        "convert_categorical_data(input_df)"
      ],
      "metadata": {
        "id": "VnaG1KO_0OZj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = input_df\n",
        "for column in categorical_columns:\n",
        "  temp_df[column] = LabelEncoder().fit_transform(temp_df[column].astype(float))\n",
        "  temp_df[column] = temp_df[column].astype('float')\n",
        "\n",
        "Y = temp_df[model_columns]\n",
        "X = temp_df[goal]"
      ],
      "metadata": {
        "id": "qwW8gOR-KRKB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(Y, X, test_size=0.1, random_state=1)"
      ],
      "metadata": {
        "id": "jW9FT4-PUKz1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space = {\n",
        "  'n_estimators':hp.quniform('n_estimators', 100, 10000, 1000),\n",
        "  'gamma':hp.uniform('gamma', 0.01, 0.1),\n",
        "  'learning_rate':hp.uniform('learning_rate', 0.00001, 0.1),\n",
        "  'max_depth':hp.quniform('max_depth', 3,7,1),\n",
        "  'subsample':hp.uniform('subsample', 0.10, 0.98),\n",
        "  'colsample_bytree':hp.uniform('colsample_bytree', 0.10, 0.98),\n",
        "  'colsample_bylevel':hp.uniform('colsample_bylevel', 0.10, 0.98),\n",
        "  'reg_lambda': hp.uniform('reg_lambda', 1, 50)\n",
        "}\n",
        "\n",
        "def objective(params):\n",
        "  params = {\n",
        "    'n_estimators': int(params['n_estimators']),\n",
        "    'gamma': params['gamma'],\n",
        "    'learning_rate': params['learning_rate'],\n",
        "    'max_depth': int(params['max_depth']),\n",
        "    'subsample': params['subsample'],\n",
        "    'colsample_bytree': params['colsample_bytree'],\n",
        "    'colsample_bylevel': params['colsample_bylevel'],\n",
        "    'reg_lambda': params['reg_lambda']}\n",
        "  xb_a = XGBRegressor(**params)\n",
        "  score = cross_val_score(xb_a, x_train, y_train, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1).mean()\n",
        "  return -score\n",
        "\n",
        "best = fmin(fn=objective, space=space, max_evals=20, rstate=np.random.RandomState(1), algo=tpe.suggest)"
      ],
      "metadata": {
        "id": "GuGtl9CQKCMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBRegressor(\n",
        "  random_state=0,\n",
        "  n_estimators=int(best['n_estimators']),\n",
        "  colsample_bytree= best['colsample_bytree'],\n",
        "  gamma= best['gamma'],\n",
        "  learning_rate= best['learning_rate'],\n",
        "  max_depth= int(best['max_depth']),\n",
        "  subsample= best['subsample'],\n",
        "  colsample_bylevel= best['colsample_bylevel'],\n",
        "  reg_lambda= best['reg_lambda'],\n",
        "  objective =\"reg:squarederror\"\n",
        ")"
      ],
      "metadata": {
        "id": "PDQMsN-87mo4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "DJhVgi3XTnNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = model.score(x_train, y_train)\n",
        "print(\"Train score {}\".format(train_score))\n",
        "\n",
        "vali_score = model.score(x_valid, y_valid)\n",
        "print(\"Validation score {}\".format(vali_score))\n",
        "\n",
        "# cv = RepeatedKFold(n_splits=2, n_repeats=2, random_state=1)\n",
        "# scores = cross_val_score(model, Y, X, cv=cv, error_score=\"raise\", scoring=\"neg_mean_absolute_error\")\n",
        "# print(\"Mean Absolute error {}\".format(absolute(scores.mean())))"
      ],
      "metadata": {
        "id": "PztIyCcQA4jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_valid)\n",
        "predictions = [value for value in y_pred]"
      ],
      "metadata": {
        "id": "XkS9V6d6Vk3z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate predictions\n",
        "rmse = np.sqrt(mean_squared_error(y_valid.values, predictions))\n",
        "print(\"RMSE {}\".format(rmse))"
      ],
      "metadata": {
        "id": "WtOmzgVo-df2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame(y_pred)\n",
        "pred.columns = [\"y_prediction\"]\n",
        "y_valid.reset_index(inplace=True)\n",
        "df2 = pred.join(y_valid)\n",
        "comparison = df2[[\"y_prediction\", \"Orders/Followers\"]]"
      ],
      "metadata": {
        "id": "zhW5lfT3oQHG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y[\"size\"].unique()"
      ],
      "metadata": {
        "id": "LNR2xYwhDmwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 10):\n",
        "  temp_value = i/10 + 0.1\n",
        "  pred_row_df = Y.describe()[Y.describe().index.isin([\"mean\"])]\n",
        "  pred_row_df[\"Posts\"] = temp_value\n",
        "  pred = model.predict(pred_row_df)\n",
        "  print(\"Post value\", temp_value)\n",
        "  print(\"\\tPrediction\", pred[0])"
      ],
      "metadata": {
        "id": "ZeoiJNvd7Fa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 4):\n",
        "  temp_value = i + 0.1\n",
        "  pred_row_df = Y.describe()[Y.describe().index.isin([\"mean\"])]\n",
        "  pred_row_df[\"size\"] = temp_value\n",
        "  pred = model.predict(pred_row_df)\n",
        "  print(\"size value\", temp_value)\n",
        "  print(\"\\tPrediction\", pred[0])"
      ],
      "metadata": {
        "id": "lhkxZ114DxWO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}